{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdQTCx47A/8TydxMoI3Oep",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveen8174/CSOC24/blob/main/Untitled3(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2Y68sezUiaxX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input,Conv2D,Dense,Flatten,Dropout,GlobalMaxPooling2D,MaxPooling2D,BatchNormalization,Lambda\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.datasets.fashion_mnist\n",
        "(train_images,train_labels),(test_images,test_labels) = dataset.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txgslTGHoJ_e",
        "outputId": "4ef8164c-b5bf-4f4c-9df3-a36122c90a63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Siamese architecture\n",
        "\n",
        "it is used for taking two inputs and finding how similar the inputs are  \n",
        "eg: face detection,...."
      ],
      "metadata": {
        "id": "59Zx16ESnJPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_base_layer():\n",
        "  input = Input(shape=(28,28))\n",
        "  x = Flatten()(input)\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  x = Dropout(0.1)(x)\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  x = Dropout(0.1)(x)\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  return Model(inputs=input,outputs=x)\n"
      ],
      "metadata": {
        "id": "CA0GTt4UnaGP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_network = initialize_base_layer()\n",
        "\n",
        "input_a = Input(shape=(28,28))\n",
        "input_b = Input(shape=(28,28))\n",
        "\n",
        "vect_output_a = base_network(input_a)\n",
        "vect_output_b = base_network(input_b)"
      ],
      "metadata": {
        "id": "6oxtyAW_ojGO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vects):\n",
        "  x,y = vects\n",
        "  sum_square = np.sum(np.square(x-y),axis=1,keepdims=True)\n",
        "  return np.sqrt(np.maximum(sum_square,np.finfo(float).eps))\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "  shape1,shape2 = shapes\n",
        "  return (shape1[0],1)\n",
        "\n",
        "output = Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([vect_output_a,vect_output_b])\n"
      ],
      "metadata": {
        "id": "zhTcGubapGkH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input_a,input_b],outputs=output)\n"
      ],
      "metadata": {
        "id": "EcClKQzGqMB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating a loss function\n",
        "\n",
        "we can either import the tf.keras.losses object of the specific loss function and hypertune the parameters or create a custom loss function\n"
      ],
      "metadata": {
        "id": "tzWwGZgDs-nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class custom:\n",
        "  def __init__(self,dataset):\n",
        "    self.tr_dataset = dataset.take(int(len(dataset)*0.8)).shuffle(len(dataset)).prefetch(tf.data.AUTOTUNE)\n",
        "    self.val_dataset = dataset.skip(int(len(dataset)*0.8))\n",
        "\n",
        "  def my_loss_threshold(threshold):\n",
        "    def my_loss(self,y_true,y_pred):\n",
        "      threshold = 1\n",
        "      error = (y_pred-y_true)\n",
        "      is_small_error = tf.abs(error) <= threshold\n",
        "      small_error_loss = tf.square(error) / 2\n",
        "      big_error_loss = threshold * (tf.abs(error) - (0.5 * threshold))\n",
        "      return tf.where(is_small_error,small_error_loss,big_error_loss)\n",
        "    return my_loss\n",
        "  def build_model(self):\n",
        "    model = Model(inputs=input,outputs=output)\n",
        "    pass\n",
        "  def model_compile(self):\n",
        "    model.compile(optimizer='adam',loss=my_loss_threshold(threshold=1))\n",
        "    return model\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "3WV8gFK7tTZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class my_huber(tf.keras.losses):\n",
        "  threshold = 1\n",
        "  def __init__(self,threshold) -> None:\n",
        "    super().__init__()\n",
        "    self.threshold= threshold\n",
        "\n",
        "  def call(self,y_pred,y_true):\n",
        "    threshold = 1\n",
        "    error = (y_pred-y_true)\n",
        "    is_small_error = tf.abs(error) <= threshold\n",
        "    small_error_loss = tf.square(error) / 2\n",
        "    big_error_loss = threshold * (tf.abs(error) - (0.5 * threshold))\n",
        "    return tf.where(is_small_error,small_error_loss,big_error_loss)\n",
        "\n",
        "model.compile(optimizer='adam',loss=my_huber(threshold=1))"
      ],
      "metadata": {
        "id": "yZMsbYaH0I4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class contrastive(tf.keras.losses):\n",
        "  def __init__(self,margin):\n",
        "    super().__init__()\n",
        "    self.margin = margin\n",
        "  def call(y_true,y_pred):\n",
        "    y_true = tf.cast(y_true,tf.float32)\n",
        "    square_pred = tf.square(y_pred)\n",
        "    margin_square = tf.square(tf.maximum(self.margin-y_pred,0))\n",
        "    return tf.reduce_mean(y_true*square_pred + (1-y_true)*margin_square)"
      ],
      "metadata": {
        "id": "rF-I1Q_k1q7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREATING A LAYER"
      ],
      "metadata": {
        "id": "w0p-Zsov3Zl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LAMBDA layers"
      ],
      "metadata": {
        "id": "SkeJ4ESN56nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.Lambda(lambda x: tf.abs(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tearsL7s55l4",
        "outputId": "0cefdf23-f0c2-4588-cc0f-78dac084f91c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Lambda name=lambda_1, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Layer\n",
        "\n",
        "class SimpleDense(Layer):\n",
        "  def __init__(self,units = 32,activation = None):\n",
        "    super(SimpleDense,self).__init__()\n",
        "    self.units = units\n",
        "    self.activation = tf.keras.activations.get(activation)\n",
        "  def build(self,input_shape): # create state\n",
        "    w_init = tf.random_normal_initializer()\n",
        "    self.w = tf.Variable(name='kernel',initial_value=w_init(shape=(input_shape[-1],self.units),dtype='float32'),trainable=True)\n",
        "\n",
        "    b_init = tf.zeros_initializer()\n",
        "    self.b = tf.Variable(name='bias',initial_value=b_init(shape=(self.units,),dtype='float32'),trainable=True)\n",
        "\n",
        "  def call(self,inputs): # computation\n",
        "    return self.activation(tf.matmul(inputs,self.w) + self.b)\n",
        "# we cannot have activation function for now but we can use Lambda layer for it"
      ],
      "metadata": {
        "id": "ZnfX0CYq3Y67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODELS\n"
      ],
      "metadata": {
        "id": "5wwKDgnxHCQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "wide and deep model"
      ],
      "metadata": {
        "id": "kAVp8J2gHGQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "fit(),evaluate(),predict()   \n",
        "are also present and can be rewritten if needed,  \n",
        "keras.utils.plot_model(),.save(),save_weights(),summary()"
      ],
      "metadata": {
        "id": "rWvjrW2SIVvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class wideAndDeep(tf.keras.Model):\n",
        "  def __init__(self,units=30,activation='relu',**kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden1 = tf.keras.layers.Dense(units,activation=activation)\n",
        "    self.hidden2 = tf.keras.layers.Dense(units,activation=activation)\n",
        "    self.main_output = tf.keras.layers.Dense(1)\n",
        "    self.aux_output = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self,inputs):\n",
        "      input_A,input_B = inputs\n",
        "      hidden1 = self.hidden1(input_B)\n",
        "      hidden2 = self.hidden2(hidden1)\n",
        "      concat = tf.keras.layers.concatenate([input_A,hidden2])\n",
        "      main_output = self.main_output(concat)\n",
        "      aux_output = self.aux_output(hidden2)\n",
        "      return main_output,aux_output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SczUTKlfHEhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNresidual(Model):\n",
        "  def __init__(self,layers,filters,**kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden = [Conv2D(filters,(3,3),activation = 'relu') for _ in range(layers)]\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = inputs\n",
        "    for layer in self.hidden:\n",
        "      x = layer(x)\n",
        "    return inputs + x\n",
        "\n",
        "\n",
        "class DNNresidual(Model):\n",
        "  def __init__(self,layers,neurons,**kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden = [Dense(neurons,(3,3),activation = 'relu') for _ in range(layers)]\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = inputs\n",
        "    for layer in self.hidden:\n",
        "      x = layer(x)\n",
        "    return inputs + x\n",
        "\n",
        "class MyResidual(Model):\n",
        "  def __init__(self,**kwargs):\n",
        "    self.hidden = Dense(30,activation='relu')\n",
        "    self.block1 = CNNresidual(2,64)\n",
        "    self.block2 = DNNresidual(2,64)\n",
        "    self.out = Dense(1)\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = self.hidden(inputs)\n",
        "    x = self.block1(x)\n",
        "    for _ in range(3):\n",
        "      x = self.block2(x)\n",
        "    return self.out(x)\n"
      ],
      "metadata": {
        "id": "R_6d37TgJrqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RESNET-18\n"
      ],
      "metadata": {
        "id": "-lGcvnZ8Vd-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IdentityBlock(Model):\n",
        "  def __init__(self,filters,kernel_size):\n",
        "    super(IdentityBlock,self).__init__()\n",
        "    self.conv1 = Conv2D(filters,kernel_size,padding='same')\n",
        "    self.bn1 = BatchNormalization()\n",
        "    self.conv2 = Conv2D(filters,kernel_size,padding='same')\n",
        "    self.bn2 = BatchNormalization()\n",
        "\n",
        "    self.act = tf.keras.layers.Activation('relu')\n",
        "    self.add = tf.keras.layers.Add()\n",
        "  def call(self,inputs):\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.bn1(x)\n",
        "    x = self.act(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.add([x,inputs])\n",
        "    x = self.act(x)\n",
        "    return x\n",
        "\n",
        "class IdenticalConvBlock(Model):\n",
        "  def __init__(self,filters,kernel_size):\n",
        "    super(IdenticalConvBlock,self).__init__()\n",
        "    self.conv1 = Conv2D(filters,kernel_size,padding='same')\n",
        "    self.bn1 = BatchNormalization()\n",
        "    self.conv2 = Conv2D(filters,kernel_size,padding='same')\n",
        "    self.bn2 = BatchNormalization()\n",
        "    self.addConv = conv2D(filters,1,padding='same')\n",
        "    self.act = tf.keras.Activation('relu')\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.bn1(x)\n",
        "    x = self.act(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.add([x,self.addConv(inputs)])\n",
        "    x = self.act(x)\n",
        "    return x\n",
        "\n",
        "class ResNet18(Model):\n",
        "  def __init__(self,num_classes):\n",
        "    super(ResNet18,self).__init__()\n",
        "    self.irb1 = IdentityBlock(64,3)\n",
        "    self.irb2 = IdentityBlock(64,3)\n",
        "    self.irb3 = IdentityBlock(64,3)\n",
        "    self.iccb = IdenticalConvBlock(64,3)\n",
        "    self.maxpool = MaxPool2D(3,strides=2,padding='same')\n",
        "    self.bn = BatchNormalization()\n",
        "    self.act = tf.keras.layers.Activation('relu')\n",
        "    self.conv = Conv2D(64,(7,7),padding='same')\n",
        "    self.globalpool = tf.keras.layers.GlobalAvergePooling2D()\n",
        "    self.out = Dense(num_classes,activation='softmax')\n",
        "  def call(self,inputs):\n",
        "    x = self.conv(inputs)\n",
        "    x = self.bn(x)\n",
        "    x = self.act(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.irb1(x)\n",
        "    x = self.irb2(x)\n",
        "    x = self.iccb(x)\n",
        "    x = self.irb3(x)\n",
        "    x = self.globalpool(x)\n",
        "    return self.out(x)\n",
        "\n",
        "resModel = ResNet18(11)\n",
        "\n"
      ],
      "metadata": {
        "id": "Lu0D2mBPVg1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CALLBACKS"
      ],
      "metadata": {
        "id": "R7PBmwNca0c7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  fit(),fit_generator()\n",
        "*  predict(),predict_generator()\n",
        "*  evaluate(),evaluate_generator()  \n",
        "\n",
        "\n",
        " are the model methods that can take callbacks  \n",
        " eg:\n",
        "* tensorboard callback\n",
        " ```\n",
        " tensorboard = tf.keras.callbacks.Tensorboard(log_dir = log_dir)\n",
        " ```\n",
        "*  model checkpoints\n",
        "```\n",
        "ModelCheckpoints(model.h5,**kwargs)\n",
        "```\n",
        "*  `EarlyStopping`  \n",
        "\n",
        "*  `CSVLogger`  \n",
        "\n",
        "\n",
        "these are few builtin callbacks"
      ],
      "metadata": {
        "id": "Cjjx5DcSNnHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vrA5kzTRP2Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class mycallbacks(tf.keras.callbacks.Callback):\n",
        "  def __init__(self,threshold):\n",
        "    super(mycallbacks,self).__init__()\n",
        "    self.threshold = threshold\n",
        "\n",
        "  def on_epoch_end(self,epoch,logs=None):\n",
        "    ratio = logs[\"val_loss\"]/logs[\"loss\"]\n",
        "    print(f\"Epoch: {epoch},val/train loss ratio: {ratio}\")\n",
        "\n",
        "    if ratio > self.threshold:\n",
        "      print(\"stopping training\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8YK353gEazld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class viscallbacks(tf.keras.callbacks.Callback):\n",
        "  def __init__(self,inputs,ground_truth,display_frequency=10,n_samples = 10):\n",
        "    super(viscallbacks,self).__init__()\n",
        "    self.inputs = inputs\n",
        "    self.ground_truth = ground_truth\n",
        "    self.image = []\n",
        "    self.display_frequency = display_frequency\n",
        "    self.n_samples = n_samples\n",
        "\n",
        "  def on_epoch_end(self,epoch,logs=None):\n",
        "    indexes = np.ranadom.choice(np.arange(len(self.inputs)),size=self.n_samples)\n",
        "    x_test, y_test = self.inputs[indexes],self.ground_truth[indexes]\n",
        "    y_pred = self.model.predict(x_test)\n",
        "    display_images(x_test,y_test,y_pred, epoch,self.display_frequency)\n",
        "    ....\n",
        "    ...."
      ],
      "metadata": {
        "id": "ccPbv92FSCpD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}